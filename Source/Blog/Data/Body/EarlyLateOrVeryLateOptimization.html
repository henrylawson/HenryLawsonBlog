<p>Optimization is a topic that is guaranteed to come up at least once during the course of a project or even perhaps once an iteration, or once every story if your project is performance critical. When working in an agile <a href="http://c2.com/cgi/wiki?TestDrivenDevelopment">TDD</a> environment the following questions often arise - <strong>Do we optimize from the beginning? Do we optimize at the end? Is this optimization something that comes under <a href="http://www.codinghorror.com/blog/2004/10/kiss-and-yagni.html">KISS and YAGNI</a>?</strong> Unfortunately like almost everything, there is never one perfect answer and it always comes down to context and requirements.</p>
<p>From my perspective there are three opportunities for optimization during agile TDD style development, these are appropriately named:</p>
<ol>
	<li>Early Optimization</li>
	<li>Late Optimization</li>
	<li>Very Late Optimization</li>
</ol>
<p><strong>Early Optimization</strong> is when it is known before the story begins that there are several <a href="http://en.wikipedia.org/wiki/Non-functional_requirement">NFR</a>'s related to this story in regards to performance. These usually exist because the story is part of a re-write of a legacy application or it is a story that is there to improve the performance of existing functionality. In these situations those <strong>NFR's should be turned into acceptance tests that can be run continuously during development</strong> to guide and ensure a well optimized solution is created that satisfies the NFR's. The important point to note about the two examples provided above is that there is evidence that <i>Early Optimization</i> is required. This is either by looking at historical data (from the legacy application) or from the performance of existing functionality. If the project is <a href="http://en.wikipedia.org/wiki/Greenfield_project">greenfield</a> and performance requirements have been thought up by over optimistic clients or developers about the usage of particular features in the application then it might be worth considering a <i>Late Optimization</i> or a <i>Very Late Optimization</i> approach instead.</p>
<p><strong>Late Optimization</strong> is the approach that should be taken <strong>for stories that don't have any concrete supporting evidence that optimization is required</strong>. <i>Late Optimization</i> is the process in which a solution to the problem is first created without optimization being considered. The simplest cleanest solution is created (<a href="http://en.wikipedia.org/wiki/KISS_principle">KISS</a>). Once this solution has passed QA and has met all functional requirements, then optimization can be considered. Before optimizing it is important that the functionality is first measured for its existing performance benchmarks. This can be done using tools like <a href="http://jmeter.apache.org/">JMeter</a>, <a href="http://gatling-tool.org/">Gatling</a> and <a href="http://httpd.apache.org/docs/2.2/programs/ab.html">Apache Benchmark</a>. Once the functionality has been benchmarked, <strong>if the results indicate that the performance does not meet a business need, then optimization should be carried out</strong> (<i>after a new optimization story is created, estimated and prioritized)</i>. The important thing to reiterate here is that the evidence was obtained to prove that performance was a problem that affected a business need, thus justifying the extra work and avoiding a violation of <a href="http://en.wikipedia.org/wiki/You_ain't_gonna_need_it">YAGNI</a>. It should go without saying that as with <i>Early Optimization</i>, the new NFR's should be written as acceptance tests prior to development. Now it might seem like a lot of fluffing around is being carried out for something that needed to be optimized from the beginning, however it is surprising how often the <a href="http://en.wikipedia.org/wiki/KISS_principle">KISS</a> solution to a problem is <i>good enough to satisfy a business need</i>. For the cases where there is too much uncertainty about whether something should be optimized, there is always <i>Very Late Optimization</i>.</p>
<p><strong>Very Late Optimization</strong> is optimization carried out on a piece of functionality after it has been released into the wild and found to not meet the performance requirements of its users. Optimization can be a very expensive operation in some circumstances, in these situations concrete evidence is required. The most indisputable form of evidence is that which is captured from real users of the application. This might seem like a failure to some people - releasing an application that fails to meet its user's performance needs. However the accumulative cost of consistently optimizing functionality too early without concrete supporting evidence - <strong>often results in bloated, untimely development of functionality and overly complex, expensive to maintain solutions</strong>. Remember, a slightly slow system is still a usable one and if the team is doing <a href="http://martinfowler.com/books/continuousDelivery.html">Continuous Delivery</a> (which they should be), the performance issue can be addressed in the next push.</p>
